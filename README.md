# ğŸ—£ï¸ Briskk Speech-to-Text Assignment

## ğŸ“Œ Introduction

Welcome to the **Briskk AI Speech-to-Text Assignment**! ğŸ¤  
This challenge will test your **AI integration, API development, and problem-solving skills** through a **structured sequence of tasks**.  

ğŸš€ **Your Goal:** Build a **real-time, noise-resilient voice-based search assistant** that:
âœ… Converts voice input (audio file or live mic input) into text.  
âœ… Suggests **smart search autocompletions** based on user intent.  
âœ… Handles **noisy background audio** and improves speech accuracy.  
âœ… Supports **real-time speech-to-search via WebSockets**.  

---

## ğŸ“‹ **Assignment Structure**
To ensure a smooth progression, complete each **task in sequence**:  

### **ğŸ”¹ Task 1: Speech Recognition API (Baseline)**
âœ… Implement a **FastAPI service** that:  
- Accepts an **audio file** and converts speech to text using **OpenAI Whisper or Mozilla DeepSpeech**.  
- Returns JSON output `{ "text": "<transcribed text>" }`.  
- **Test Input:** `sample_data/clean_audio/sample_english.wav`  
- **Expected Output:** `"Find me a red dress"`  

**ğŸ“Œ API:**  
```http
POST /api/voice-to-text
Content-Type: multipart/form-data
```  

---

### **ğŸ”¹ Task 2: Handle Noisy Audio (Advanced AI Processing)**
âœ… Enhance speech recognition by:  
- **Filtering background noise** using **RNNoise, DeepFilterNet, or PyDub**.  
- Comparing accuracy with and without noise removal.  
- **Test Input:** `sample_data/noisy_audio/sample_noisy.wav`  
- **Expected Output (after denoising):** `"Find me a red dress"`  

**ğŸ“Œ Evaluation Criteria:**  
âœ” Speech accuracy **before vs after** noise removal.  
âœ” Processing **time must remain <1s**.  

---

### **ğŸ”¹ Task 3: Smart Search Autocomplete (AI Ranking)**
âœ… Implement an API that:  
- **Suggests relevant results** based on user **intent & previous searches**.  
- **Ranks results dynamically** based on **popularity & trends**.  
- **Test Input:** `"find me"`  
- **Expected Output:** `[ "find me a red dress", "find me a jacket" ]`  

**ğŸ“Œ API:**  
```http
GET /api/autocomplete?q=find+me
```  

**ğŸ“Œ How to Improve?**  
- Store previous searches in **Redis** for ranking.  
- Use **AI embeddings (OpenAI or BERT)** for better matching.  

---

### **ğŸ”¹ Task 4(optional): Real-Time Speech-to-Search (WebSockets)**
âœ… Upgrade the system to **process live speech queries** via WebSockets:  
- Accept **real-time audio streams**.  
- **Continuously transcribe & autocomplete** results dynamically.  
- **Test:** Use a **live microphone** input.  

**ğŸ“Œ API WebSocket:**  
```ws
/ws/speech-to-search
```  

âœ” **Bonus**: Deploy the system using **Docker & AWS Lambda**.  

---

## ğŸ”¬ **Test Cases** (For Self-Validation)

| **Test Case** | **Input** | **Expected Output** |
|--------------|----------|----------------|
| **Speech Recognition** | `sample_data/clean_audio/sample_english.wav` | `"Find me a red dress"` |
| **Noisy Speech** | `sample_data/noisy_audio/sample_noisy.wav` | `"Find me a red dress"` |
| **Autocomplete Query** | `"find me"` | `["find me a red dress", "find me a jacket"]` |
| **Live Streaming** | Microphone | Real-time suggestions |

ğŸ“‚ All **sample audio files** are provided in `sample_data/`.  

---

## ğŸ—ï¸ **Setup & Running Instructions**

### **1ï¸âƒ£ Install Dependencies**
```bash
pip install fastapi uvicorn openai-whisper soundfile numpy scipy
```

### **2ï¸âƒ£ Run the API**
```bash
uvicorn src.main:app --reload
```

### **3ï¸âƒ£ Test API**
- Open **Swagger Docs** â†’ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)  
- Upload `sample_audio_english.wav` and check transcription accuracy.  

---

## ğŸš€ **Submission Guidelines**

ğŸ“Œ **Fork this repo & create a new branch `candidate-<yourname>`**.  
ğŸ“Œ **Push your implementation & submit a Pull Request (PR)**.  
ğŸ“Œ **Explain your approach in a README**.  

For questions, contact us at: **wizard@briskk.one**  

---

## ğŸ“© **Contact & Discussion**

ğŸ“¢ Have questions? Drop an email at **wizard@briskk.one** ğŸš€
